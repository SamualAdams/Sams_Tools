{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B1 Orders Pipeline - Bronze to Gold\n",
    "\n",
    "**Purpose**: Transform B1 sales orders into a standardized gold layer fact table for demand planning and analytics.\n",
    "\n",
    "**Source**: `ent_dse_dev.1_b1_bronze.sales_order` + `sales_order_rows`  \n",
    "**Target**: `resources/gold/orders_fact`\n",
    "\n",
    "**Architecture**: Follows Unix-like tool composition with medallion architecture patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Core tools\nfrom tools.tool__workstation import get_spark\nfrom tools.tool__dag_chainer import DagChain\nfrom tools.tool__table_polisher import polish\nfrom tool__table_indexer import TableIndexer\n\n# PySpark functions for DataFrame operations\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.types import *\n\n# Initialize Spark session and workflow chain\nspark = get_spark(\"local_delta\")\nchain__gold_orders = DagChain()\n\nprint(\"âœ… Spark session initialized\")\nprint(\"âœ… DAG chain ready for orders pipeline\")\nprint(\"âœ… PySpark functions imported\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Base Data Import & Join\n",
    "\n",
    "Join sales order headers with line items, extracting key business fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load source tables and join with minimal filtering - preserve all columns\nheaders = spark.table(\"ent_dse_dev.`1_b1_bronze`.sales_order\")\nrows = spark.table(\"ent_dse_dev.`1_b1_bronze`.sales_order_rows\")\n\n# Join and apply only essential filters - keep ALL columns from both tables\nchain__gold_orders.dag__import_orders_base = headers.join(\n    rows, \n    [\"ZSOURCE\", \"DocEntry\"], \n    \"inner\"\n).filter(\n    (F.col(\"CANCELED\") != \"Y\") &  # Exclude canceled orders\n    (F.col(\"ItemCode\").isNotNull())  # Exclude non-item lines\n)\n\nprint(f\"âœ… Base orders data loaded with ALL source columns\")\nprint(f\"   Total columns: {len(chain__gold_orders.dag__import_orders_base.columns)}\")\nprint(f\"   Total records: {chain__gold_orders.dag__import_orders_base.count():,}\")\nprint(f\"   Sample columns: {chain__gold_orders.dag__import_orders_base.columns[:10]}\")\n\n# Show structure\nchain__gold_orders.look(0)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Standardization\n",
    "\n",
    "Apply table polishing for consistent column naming and formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply standardization\n",
    "chain__gold_orders.dag__polish_orders = polish(\n",
    "    chain__gold_orders.dag__import_orders_base\n",
    ")\n",
    "\n",
    "print(\"âœ… Table polishing applied\")\n",
    "print(\"Column standardization:\")\n",
    "for col in chain__gold_orders.dag__polish_orders.columns[:10]:\n",
    "    print(f\"  - {col}\")\n",
    "print(\"  ... (and more)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Entity Indexing\n",
    "\n",
    "Create dimensional indices for customers, items, and warehouses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize indexer with polished data\n",
    "indexer = TableIndexer(chain__gold_orders.dag__polish_orders)\n",
    "\n",
    "# Create entity indices\n",
    "print(\"Creating entity indices...\")\n",
    "\n",
    "customer_result = indexer.customer(\"zsource\", \"customer_code\")\n",
    "print(f\"âœ… Customer indexing: {customer_result['mapping'].count():,} unique customers\")\n",
    "\n",
    "item_result = indexer.item(\"zsource\", \"item_code\")\n",
    "print(f\"âœ… Item indexing: {item_result['mapping'].count():,} unique items\")\n",
    "\n",
    "warehouse_result = indexer.warehouse(\"zsource\", \"warehouse_code\")\n",
    "print(f\"âœ… Warehouse indexing: {warehouse_result['mapping'].count():,} unique warehouses\")\n",
    "\n",
    "# Get the fully indexed DataFrame\n",
    "chain__gold_orders.dag__indexed_orders = indexer.filtered_indexed_df\n",
    "print(f\"âœ… Indexed orders: {chain__gold_orders.dag__indexed_orders.count():,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Business Logic Enrichment\n",
    "\n",
    "Add calculated fields and business intelligence metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Add business enrichments using simple withColumns pattern (case study style)\nchain__gold_orders.dag__enriched = chain__gold_orders.pick(-1).withColumns({\n    \"calc_delivery_fill_rate\": F.when(F.col(\"quantity\") > 0, F.col(\"delivrdqty\") / F.col(\"quantity\")).otherwise(0),\n    \"calc_open_fill_rate\": F.when(F.col(\"quantity\") > 0, F.col(\"openqty\") / F.col(\"quantity\")).otherwise(0),\n    \"calc_order_age_days\": F.datediff(F.current_date(), F.to_date(F.col(\"docdate\"), \"yyyy-MM-dd\")),\n    \"calc_fiscal_year\": F.year(F.to_date(F.col(\"docdate\"), \"yyyy-MM-dd\")),\n    \"calc_fiscal_quarter\": F.quarter(F.to_date(F.col(\"docdate\"), \"yyyy-MM-dd\")),\n    \"calc_delivery_performance\": F.when(F.col(\"actdeldate\").isNull(), \"Pending\")\n                                   .when(F.to_date(F.col(\"actdeldate\"), \"yyyy-MM-dd\") > F.to_date(F.col(\"docduedate\"), \"yyyy-MM-dd\"), \"Late\")\n                                   .otherwise(\"On Time\"),\n    \"calc_delivered_value\": F.col(\"delivrdqty\") * F.col(\"price\"),\n    \"calc_open_value\": F.col(\"openqty\") * F.col(\"price\")\n})\n\nprint(\"âœ… Business enrichments added using simple withColumns pattern\")\nchain__gold_orders.look(-1)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Quality Validation\n",
    "\n",
    "Add data quality flags and business rule validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Simple quality filtering using basic checks (case study style)\nchain__gold_orders.dag__quality_filtered = chain__gold_orders.pick(-1).filter(\n    (F.col(\"cardcode\").isNotNull()) &\n    (F.col(\"itemcode\").isNotNull()) &\n    (F.col(\"quantity\") > 0) &\n    (F.col(\"price\") >= 0) &\n    (F.col(\"docdate\").isNotNull())\n)\n\nprint(\"âœ… Quality filtering applied using simple filter operations\")\nprint(f\"Records after quality filter: {chain__gold_orders.dag__quality_filtered.count():,}\")\nchain__gold_orders.trace(shape=True)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final Gold Layer Structure\n",
    "\n",
    "Create the final fact table with clean, organized columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Add final metadata and write to gold layer (case study style)\nchain__gold_orders.dag__final_gold = chain__gold_orders.pick(-1).withColumns({\n    \"meta_order_line_key\": F.concat_ws(\"-\", F.col(\"zsource\"), F.col(\"docentry\"), F.col(\"linenum\")),\n    \"meta_etl_processed_at\": F.current_timestamp(),\n    \"meta_etl_source\": F.lit(\"b1_orders_pipeline_v1\")\n})\n\nprint(f\"âœ… Final gold orders: {chain__gold_orders.dag__final_gold.count():,} records\")\nprint(f\"   Total columns: {len(chain__gold_orders.dag__final_gold.columns)}\")\n\n# Show final workflow\nchain__gold_orders.trace(shape=True)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Persistence & Quality Reporting\n",
    "\n",
    "Save to gold layer and provide comprehensive inspection capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Write to gold layer (case study style)\n(chain__gold_orders.pick(-1)\n    .write.format(\"delta\")\n    .mode(\"overwrite\")\n    .save(\"resources/gold/orders_fact\"))\n\nprint(\"âœ… Data written to resources/gold/orders_fact\")\n\n# Save entity mappings\nfor kind, mapping in {\n    \"customer\": customer_result['mapping'],\n    \"item\": item_result['mapping'], \n    \"warehouse\": warehouse_result['mapping']\n}.items():\n    (mapping.write.format(\"delta\")\n        .mode(\"overwrite\")\n        .save(f\"resources/gold/map__{kind}s\"))\n\nprint(\"âœ… Entity mappings saved\")\nprint(\"ðŸŽ‰ B1 Orders Pipeline Complete!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Pipeline Inspection & Analytics\n",
    "\n",
    "Comprehensive data quality and business intelligence reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Pipeline inspection using built-in DagChain methods\nprint(\"ðŸ“‹ B1 Orders Pipeline Summary\")\nprint(\"=\" * 40)\n\n# Use built-in trace method\nchain__gold_orders.trace(shape=True)\n\n# Simple summary\nprint(f\"\\\\nâœ… Pipeline complete:\")\nprint(f\"   - {customer_result['mapping'].count():,} customers indexed\")\nprint(f\"   - {item_result['mapping'].count():,} items indexed\") \nprint(f\"   - {warehouse_result['mapping'].count():,} warehouses indexed\")\n\n# Use built-in look method for final check\nprint(\"\\\\nFinal data sample:\")\nchain__gold_orders.look(-1)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Quick Access Functions\n",
    "\n",
    "Utility functions for easy data access and exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Quick data access (simple, no custom functions)\ndef load_orders():\n    return spark.read.format(\"delta\").load(\"resources/gold/orders_fact\")\n\nprint(\"âœ… Simple utility function available:\")\nprint(\"  - load_orders() â†’ Access gold orders fact table\")\nprint(\"\\\\nUse DagChain built-in methods for inspection:\")\nprint(\"  - chain__gold_orders.trace() â†’ See workflow steps\") \nprint(\"  - chain__gold_orders.look(n) â†’ View DataFrame n\")\nprint(\"  - chain__gold_orders.pick(n) â†’ Get DataFrame n\")\nprint(\"\\\\nðŸŽ‰ Clean, tool-focused B1 Orders Pipeline!\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Demand Planning Agent",
   "language": "python",
   "name": "demand_planning_agent"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}